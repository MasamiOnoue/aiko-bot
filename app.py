import os
import traceback
import logging
import datetime
import threading
import time
import json
import re
import feedparser #ãƒ–ãƒ­ã‚°ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
import pytz
from flask import Flask, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage, FollowEvent
from dotenv import load_dotenv
from openai import OpenAI
from google.oauth2 import service_account
from googleapiclient.discovery import build
import logging  #é€šä¿¡ãƒ­ã‚°ã‚’Renderã«å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

load_dotenv()

# æ—¥æœ¬æ¨™æº–æ™‚ (JST) ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = pytz.timezone('Asia/Tokyo')

SERVICE_ACCOUNT_FILE = 'aiko-bot-log-cfbf23e039fd.json'
SPREADSHEET_ID1 = os.getenv('SPREADSHEET_ID1')  # ä¼šè©±ãƒ­ã‚°
SPREADSHEET_ID2 = os.getenv('SPREADSHEET_ID2')  # å¾“æ¥­å“¡æƒ…å ±
SPREADSHEET_ID3 = os.getenv('SPREADSHEET_ID3')  # å–å¼•å…ˆæƒ…å ±
SPREADSHEET_ID4 = os.getenv('SPREADSHEET_ID4')  # ä¼šç¤¾æƒ…å ±
SPREADSHEET_ID5 = os.getenv('SPREADSHEET_ID5')  # æ„›å­ã®çµŒé¨“ãƒ­ã‚°

cache_lock = threading.Lock()
recent_user_logs = {}
employee_info_map = {}
last_greeting_time = {}

SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
creds = service_account.Credentials.from_service_account_file(
    SERVICE_ACCOUNT_FILE, scopes=SCOPES
)
sheets_service = build('sheets', 'v4', credentials=creds)
sheet = sheets_service.spreadsheets()

# ==== ä¼šç¤¾æƒ…å ±ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®åˆ—æ§‹æˆå®šç¾© ====
COMPANY_INFO_COLUMNS = {
    "ã‚«ãƒ†ã‚´ãƒª": 0,
    "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": 1,
    "è³ªå•ä¾‹": 2,
    "å›ç­”å†…å®¹": 3,
    "å›ç­”è¦ç´„": 4,
    "è£œè¶³æƒ…å ±": 5,
    "æœ€çµ‚æ›´æ–°æ—¥": 6,
    "ç™»éŒ²è€…å": 7,
    "ä½¿ç”¨å›æ•°": 8,
    "æ‹…å½“è€…": 9,
    "é–‹ç¤ºç¯„å›²": 10,
    "äºˆå‚™2": 11,
    "äºˆå‚™3": 12,
    "äºˆå‚™4": 13,
    "äºˆå‚™5": 14,
    "äºˆå‚™6": 15,
    "äºˆå‚™7": 16,
    "äºˆå‚™8": 17,
    "äºˆå‚™9": 18,
    "äºˆå‚™10": 19,
    "äºˆå‚™11": 20,
    "äºˆå‚™12": 21,
    "äºˆå‚™13": 22,
    "äºˆå‚™14": 23,
    "äºˆå‚™15": 24,
    "äºˆå‚™16": 25
}

def now_jst():
    return datetime.datetime.now(pytz.timezone("Asia/Tokyo"))

def get_time_based_greeting():
    current_time = now_jst()
    logging.info(f"ç¾åœ¨ã®JSTæ™‚åˆ»: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
    hour = current_time.hour
    if 5 <= hour < 10:
        return "ãŠã£ã¯ãƒ¼ã€‚"
    elif 10 <= hour < 18:
        return "ã‚„ã£ã¯ã‚ãƒ¼ã€‚"
    elif 18 <= hour < 23:
        return "ãŠã£ã¤ã€œã€‚"
    else:
        return "ã­ã‚€ã­ã‚€ã€‚"

def get_user_summary(user_id):
    try:
        result = sheet.values().get(
            spreadsheetId=SPREADSHEET_ID5,
            range='çµŒé¨“ãƒ­ã‚°!A2:D'
        ).execute()
        rows = result.get("values", [])
        for row in reversed(rows):
            if row[1] == user_id and len(row) >= 4:
                return row[3]  # è¦ç´„å†…å®¹
    except Exception as e:
        logging.error(f"{user_id} ã®çµŒé¨“ãƒ­ã‚°å–å¾—å¤±æ•—: {e}")
    return ""
    
# æ„›å­ã®çµŒé¨“ãƒ­ã‚°ï¼ã¤ã¾ã‚Šæ—¥è¨˜ã®æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
def get_recent_summaries(count=5):
    try:
        result = sheet.values().get(
            spreadsheetId=SPREADSHEET_ID5,
            range='çµŒé¨“ãƒ­ã‚°!A2:C'
        ).execute()
        rows = result.get("values", [])[-count:]
        return "\n".join(f"ã€{r[2]}ã€‘{r[3]}" for r in rows if len(r) >= 4)
    except Exception as e:
        logging.error(f"å…¨ä½“ã®çµŒé¨“ãƒ­ã‚°å–å¾—å¤±æ•—: {e}")
        return ""
        
# ä¼šè©±ãƒ­ã‚°ã®æƒ…å ±ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°       
def log_conversation(timestamp, user_id, user_name, speaker, message, status="OK"):
    try:
        values = [[
            timestamp,
            user_id,
            user_name or "ä¸æ˜",
            speaker,
            message,
            "é‡è¦" if status == "é‡è¦" else "æœªåˆ†é¡",  # â† ã“ã“ã§é‡è¦ã‚’åæ˜ 
            "text",
            "",
            status,
            ""
        ]]
        sheet.values().append(
            spreadsheetId=SPREADSHEET_ID1,
            range='ä¼šè©±ãƒ­ã‚°!A:J',
            valueInputOption='USER_ENTERED',
            body={'values': values}
        ).execute()
    except Exception as e:
        logging.error("ãƒ­ã‚°ä¿å­˜å¤±æ•—: %s", e)
        
def refresh_cache():
    global recent_user_logs
    try:
        result = sheet.values().get(
            spreadsheetId=SPREADSHEET_ID1,
            range='ä¼šè©±ãƒ­ã‚°!A2:J'
        ).execute()
        rows = result.get("values", [])[-100:]
        with cache_lock:
            recent_user_logs = {
                row[1]: [r for r in rows if r[1] == row[1] and r[3] == "ãƒ¦ãƒ¼ã‚¶ãƒ¼"][-10:]
                for row in rows if len(row) >= 4
            }
    except Exception as e:
        logging.error("ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°å¤±æ•—: %s", e)

def load_employee_info():
    global employee_info_map
    try:
        result = sheet.values().get(
            spreadsheetId=SPREADSHEET_ID2,
            range='å¾“æ¥­å“¡æƒ…å ±!A2:Z'
        ).execute()
        rows = result.get("values", [])
        headers = rows[0]
        for row in rows[1:]:
            data = dict(zip(headers, row))
            uid = data.get("LINEã®UID")
            if uid:
                employee_info_map[uid] = data
    except Exception as e:
        logging.error("å¾“æ¥­å“¡æƒ…å ±ã®èª­ã¿è¾¼ã¿å¤±æ•—: %s", e)

threading.Thread(target=lambda: (lambda: [refresh_cache() or load_employee_info() or time.sleep(300) for _ in iter(int, 1)])(), daemon=True).start()

app = Flask(__name__)

line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

SPREADSHEET_IDS = [
    SPREADSHEET_ID1,
    SPREADSHEET_ID2,
    SPREADSHEET_ID3,
    SPREADSHEET_ID4,
    SPREADSHEET_ID5
]

@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers["X-Line-Signature"]
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    except Exception:
        traceback.print_exc()
        abort(500)
    return "OK", 200

@handler.add(FollowEvent)
def handle_follow(event):
    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text="æ„›å­ã§ã™ã€‚ãŠå‹ã ã¡ç™»éŒ²ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚")
    )

#ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰å¾“æ¥­å“¡æƒ…å ±ã‚’SPREADSHEETã‹ã‚‰æŒã£ã¦ãã‚‹å°‚ç”¨é–¢æ•°
def search_employee_info_by_keywords(query):
    attribute_keywords = {
        "åå‰": ["åå‰", "æ°å"],
        "åå‰ã®èª­ã¿": ["åå‰ã®èª­ã¿", "èª­ã¿", "ã‚ˆã¿"],
        "å½¹è·": ["å½¹è·", "è‚©æ›¸", "ãƒã‚¹ãƒˆ", "ä»•äº‹", "å½¹å‰²"],
        "å…¥ç¤¾å¹´": ["å…¥ç¤¾å¹´", "å…¥ç¤¾", "æœ€åˆã®å¹´"],
        "ç”Ÿå¹´æœˆæ—¥": ["ç”Ÿå¹´æœˆæ—¥", "ç”Ÿã¾ã‚Œ", "èª•ç”Ÿæ—¥", "ãƒãƒ¼ã‚¹ãƒ‡ãƒ¼"],
        "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹": ["ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", "ãƒ¡ãƒ¼ãƒ«", "e-mail", "é€£çµ¡", "ã‚¢ãƒ‰ãƒ¬ã‚¹", "ãƒ¡ã‚¢ãƒ‰"],
        "æºå¸¯é›»è©±ç•ªå·": ["æºå¸¯é›»è©±ç•ªå·", "æºå¸¯", "æºå¸¯ç•ªå·", "æºå¸¯é›»è©±", "é›»è©±ç•ªå·", "æºå¸¯ã¯", "æºå¸¯ç•ªå·ã¯", "æºå¸¯é›»è©±ç•ªå·ã¯", "é€£çµ¡å…ˆ"],
        "è‡ªå®…é›»è©±": ["è‡ªå®…é›»è©±", "é›»è©±", "ç•ªå·", "é›»è©±ç•ªå·", "è‡ªå®…ã®é›»"],
        "ä½æ‰€": ["ä½æ‰€", "æ‰€åœ¨åœ°", "å ´æ‰€", "ã©ã“"],
        "éƒµä¾¿ç•ªå·": ["éƒµä¾¿ç•ªå·", "ã€’", "éƒµä¾¿"],
        "ç·Šæ€¥é€£çµ¡å…ˆ": ["ç·Šæ€¥é€£çµ¡å…ˆ", "ç·Šæ€¥", "å•ã„åˆã‚ã›å…ˆ", "è‡³æ€¥é€£çµ¡"],
        "ãƒšãƒƒãƒˆæƒ…å ±": ["ãƒšãƒƒãƒˆæƒ…å ±", "çŠ¬", "çŒ«", "ã„ã¬", "ã‚¤ãƒŒ", "ãƒã‚³", "ã­ã“", "ã«ã‚ƒã‚“ã“", "ã‚ã‚“ã¡ã‚ƒã‚“", "ã‚ã‚“ã“"],
        "æ€§æ ¼": ["æ€§æ ¼", "å¤§äººã—ã„", "ã†ã‚‹ã•ã„", "æ€§è³ª", "ç‰¹æ€§"],
        "å£ç™–": ["å£ç™–", "ã‚ˆãè¨€ã†", "ã‚ˆãèªã‚‹", "è»Ÿç€é™¸"],
        "å‚™è€ƒ": ["å‚™è€ƒ", "ãã®ä»–"],
        "è¿½åŠ æƒ…å ±": ["è¿½åŠ æƒ…å ±", "éƒ¨ç½²", "éƒ¨é–€", "éƒ¨"],
        "å®¶æ—": ["å®¶æ—", "é…å¶è€…", "å¦»", "å¤«", "å­ä¾›", "æ‰¶é¤Š", "ãƒšãƒƒãƒˆ", "çŠ¬", "çŒ«", "ã„ã¬", "ã­ã“", "ã‚ã‚“ã¡ã‚ƒã‚“"]
    }

    result_texts = []
    lowered_query = query.lower()
    for uid, data in employee_info_map.items():
        for attr, keywords in attribute_keywords.items():
            for keyword in keywords:
                if keyword.lower() in lowered_query:
                    value = data.get(attr) or data.get(attr.replace("æºå¸¯é›»è©±ç•ªå·", "æºå¸¯ç•ªå·"))
                    if not value:
                        continue  # å€¤ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    if attr not in data:
                        continue  # ç„¡åŠ¹ãªã‚­ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã‚‚ã‚¹ã‚­ãƒƒãƒ—
                    result_texts.append(f"ğŸ“Œ {data.get('åå‰', 'ä¸æ˜')}ã®{attr}ã¯ã€Œ{value}ã€ã§ã™ã€‚")
    # ğŸ” fallbackæ¤œç´¢ã®ãŸã‚ã€result_textsãŒç©ºã§ã‚‚returnã—ãªã„
    if result_texts:
        return "\n".join(result_texts)

    # fallbackæ¤œç´¢ï¼ˆæ›–æ˜§ä¸€è‡´ï¼‰
    keywords = query.split()
    for data in employee_info_map.values():
        if any(k in str(data.values()) for k in keywords):
            return "ğŸ” ç¤¾å†…æƒ…å ±ã‹ã‚‰è¦‹ã¤ã‘ã¾ã—ãŸ: " + ", ".join(f"{k}: {v}" for k, v in data.items())

    return "âš ï¸ ç¤¾å†…æƒ…å ±ã§ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

# ==== è‡ªå‹•æ—¥è¨˜ã‚’OpenAIã«ã‚„ã‚‰ã›ã‚‹é–¢æ•°ï¼ˆæ¯æ—¥3æ™‚ã«å‘¼ã³å‡ºã™ï¼‰ ====
def generate_daily_summaries(logs_by_user, sheet, client, SPREADSHEET_ID5):
    for (uid, name), messages in logs_by_user.items():
        context = "\n".join(messages)
        prompt = [
            {"role": "system", "content": (
                "ã‚ãªãŸã¯LINEã§ç¤¾å“¡ã¨æ—¥ã€…ä¼šè©±ã—ã¦ã„ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€æ„›å­ã€ã§ã™ã€‚\n"
                "ä»¥ä¸‹ã¯ã‚ãªãŸãŒæ˜¨æ—¥ã€ç¤¾å“¡ã¨äº¤ã‚ã—ãŸä¼šè©±ã®è¨˜éŒ²ã§ã™ã€‚\n"
                "æ„Ÿæƒ…ãƒ»æ€è€ƒãƒ»è¡Œå‹•ãƒ»èª²é¡Œãƒ»å°è±¡ãªã©ã‚’è¸ã¾ãˆã€ç¤¾å“¡ã¨ã®ã‚„ã‚Šå–ã‚Šã‚’æŒ¯ã‚Šè¿”ã‚‹æ—¥è¨˜ã¨ã—ã¦"
                "è‡ªåˆ†ã®ç›®ç·šã§2000æ–‡å­—ä»¥å†…ã§è‡ªç„¶ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n"
                "ä¸»èªã¯ã€ç§ã€ã‚’ç”¨ã„ã€ç¤¾å“¡ã‚’ã€â—‹â—‹ã•ã‚“ã€ãªã©ã¨å‘¼ã³ã€ç¬¬ä¸‰è€…è¦–ç‚¹ã§ã¯ãªãä¸»è¦³çš„ã«æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
                "ã¾ãŸã€è¦ç´„æ–‡ä¸­ã«æ”¹è¡Œã¯ä½¿ç”¨ã›ãšã€ã™ã¹ã¦ã®å†…å®¹ã‚’å‰Šé™¤ã›ãšã«æƒ…å ±ã‚’åœ§ç¸®ã—ã¦ç°¡æ½”ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚"
            )},
            {"role": "user", "content": context}
        ]
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=prompt,
                max_tokens=800
            )
            summary = response.choices[0].message.content.strip().replace("\n", " ")  # æ”¹è¡Œé™¤å»
            sheet.values().append(
                spreadsheetId=SPREADSHEET_ID5,
                range='çµŒé¨“ãƒ­ã‚°!A:B',
                valueInputOption='USER_ENTERED',
                body={'values': [[now_jst().isoformat(), summary]]}
            ).execute()
            logging.info(f"{name} ã®è¦ç´„ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            logging.error(f"{name} ã®è¦ç´„å¤±æ•—: {e}")

# ==== è‡ªå‹•æ—¥è¨˜è¦ç´„ï¼ˆæ¯æ—¥3æ™‚ã«å®Ÿè¡Œï¼‰ ====
def summarize_daily_conversations():
    try:
        start_time = (now_jst() - datetime.timedelta(days=1)).replace(hour=3, minute=0, second=0, microsecond=0)
        end_time = start_time + datetime.timedelta(hours=24)
        logging.info(f"è¦ç´„å¯¾è±¡æœŸé–“: {start_time} ã€œ {end_time}")

        result = sheet.values().get(
            spreadsheetId=SPREADSHEET_ID1,
            range='ä¼šè©±ãƒ­ã‚°!A2:J'
        ).execute()
        rows = result.get("values", [])

        filtered = []
        for r in rows:
            if len(r) >= 5:
                try:
                    dt = datetime.datetime.fromisoformat(r[0])
                    if dt.tzinfo is None:
                        dt = JST.localize(dt)
                    if start_time <= dt < end_time:
                        filtered.append(r)
                except Exception as e:
                    logging.warning(f"æ—¥æ™‚å¤‰æ›ã‚¨ãƒ©ãƒ¼: {r[0]} - {e}")

        if not filtered:
            logging.info("å¯¾è±¡æœŸé–“ã®ä¼šè©±ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        logs_by_user = {}
        important_entries = []
        for row in filtered:
            uid = row[1]
            name = row[2]
            message = row[4]
            status = row[9] if len(row) > 9 else ""
            logs_by_user.setdefault((uid, name), []).append(message)
            if status == "é‡è¦":
                important_entries.append((uid, name, message))

        # è¦ç´„ç”Ÿæˆ
        generate_daily_summaries(logs_by_user, sheet, client, SPREADSHEET_ID5)

        # é‡è¦æƒ…å ±ã‚’ä¼šç¤¾æƒ…å ±ã«è¨˜éŒ²
        for uid, name, msg in important_entries:
            try:
                values = [[
                    "ä¼šè©±ãƒ¡ãƒ¢",   # ã‚«ãƒ†ã‚´ãƒª
                    "ãªã—",       # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                    clean_log_message(msg[:30]),    # è³ªå•ä¾‹ï¼ˆ30æ–‡å­—ç¨‹åº¦ï¼‰
                    clean_log_message(msg),         # å›ç­”å†…å®¹
                    clean_log_message(msg[:100]),    # å›ç­”è¦ç´„ï¼ˆ100æ–‡å­—ç¨‹åº¦ï¼‰
                    "LINEä¼šè©±ãƒ­ã‚°ã‚ˆã‚Šè‡ªå‹•ç™»éŒ²",  # è£œè¶³æƒ…å ±
                    now_jst().strftime("%Y-%m-%d"),  # æœ€çµ‚æ›´æ–°æ—¥
                    "æ„›å­",        # ç™»éŒ²è€…å
                    0,           # ä½¿ç”¨å›æ•°
                    name,      # æ‹…å½“è€…
                    "ç¤¾å†…"   # é–‹ç¤ºç¯„å›²
                ] + [""] * 14]  # æ®‹ã‚Šã®äºˆå‚™2ã€œäºˆå‚™16ã‚’ç©ºã§åŸ‹ã‚ã‚‹
                
                sheet.values().append(
                    spreadsheetId=SPREADSHEET_ID4,
                    range='ä¼šç¤¾æƒ…å ±!A2:Z',
                    valueInputOption='USER_ENTERED',
                    body={'values': values}
                ).execute()
                logging.info(f"{name} ã®é‡è¦æƒ…å ±ã‚’ä¼šç¤¾æƒ…å ±ã«ä¿å­˜ã—ã¾ã—ãŸ")
            except Exception as e:
                logging.error(f"{name} ã®ä¼šç¤¾æƒ…å ±ç™»éŒ²å¤±æ•—: {e}")
    except Exception as e:
        logging.error(f"æ—¥è¨˜é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")

# ==== æ„›å­æ—¥è¨˜ã‹ã‚‰æ¯æ—¥ã®å›ç­”ã‚’å‚ç…§ã¨ã™ã‚‹ ====
def get_recent_experience_summary(sheet, user_name):
    try:
        result = sheet.values().get(
            spreadsheetId=SPREADSHEET_ID5,
            range='çµŒé¨“ãƒ­ã‚°!A:B'
        ).execute().get("values", [])
        # æœ€æ–°ã®5ä»¶ã‚’é€†é †ã§ãƒ•ã‚£ãƒ«ã‚¿
        recent_summaries = [
            row[1] for row in reversed(result[-50:]) if user_name in row[1]
        ][:5]
        return " ".join(recent_summaries)
    except Exception as e:
        logging.error(f"çµŒé¨“ãƒ­ã‚°ã®èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return ""

# ==== ä¼šç¤¾æƒ…å ±ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã—ã€è©²å½“å†…å®¹ã‚’è¿”ã™é–¢æ•° ====
def search_company_info_by_keywords(user_message, user_name, user_data):
    try:
        result = sheet.values().get(
            spreadsheetId=SPREADSHEET_ID4,
            range='ä¼šç¤¾æƒ…å ±!A2:Z'
        ).execute()
        rows = result.get("values", [])
        lowered_query = user_message.lower()
        matched_rows = []

        for idx, row in enumerate(rows):
            searchable_text = " ".join(row[:5]).lower()
            if any(k in searchable_text for k in lowered_query.split()):
                # â–¼â–¼â–¼ é–‹ç¤ºç¯„å›²ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ  â–¼â–¼â–¼
                user_aliases = get_user_aliases(user_data)
                disclosure = row[10] if len(row) > 10 else ""  # ã“ã‚ŒãŒãªã„ã¨æ¤œç´¢ãŒæ­¢ã¾ã‚‹ï¼
                if disclosure in ["", "å…¨å“¡", "ç¤¾å†…", "å€‹äºº"]:
                    matched_rows.append((idx, row))
                elif any(alias in disclosure for alias in user_aliases):
                    matched_rows.append((idx, row))
                elif any(disclosure in alias for alias in user_aliases):
                    matched_rows.append((idx, row))
                # â–²â–²â–² ã“ã®éƒ¨åˆ†ãŒãªã‘ã‚Œã°ã€å€‹åˆ¥åˆ¶é™ãŒåŠ¹ã‹ãªã„ â–²â–²â–²
        if not matched_rows:
            return None

        reply_text = "ğŸ“˜ä¼šç¤¾æƒ…å ±ã‚ˆã‚Š:"
        for idx, row in matched_rows[:3]:  # æœ€å¤§3ä»¶ã¾ã§
            question = row[2] if len(row) > 2 else "(ä¾‹ãªã—)"
            answer = row[3] if len(row) > 3 else "(å†…å®¹ãªã—)"
            registered_by = row[7] if len(row) > 7 else "(ä¸æ˜)"
            reply_text += f"ãƒ»{question} â†’ {answer}ï¼ˆç™»éŒ²è€…: {registered_by}ï¼‰\n"

            # ä½¿ç”¨å›æ•°ã‚’+1ã—ã¦æ›´æ–°
            try:
                count_cell = f'I{idx + 2}'
                current_count = row[8] if len(row) > 8 else "0"
                new_count = str(int(current_count) + 1)
                sheet.values().update(
                    spreadsheetId=SPREADSHEET_ID4,
                    range=f'ä¼šç¤¾æƒ…å ±!{count_cell}',
                    valueInputOption='USER_ENTERED',
                    body={'values': [[new_count]]}
                ).execute()
            except Exception as update_error:
                logging.warning(f"ä½¿ç”¨å›æ•°æ›´æ–°å¤±æ•—: {update_error}")

        return reply_text.strip()

    except Exception as e:
        logging.error(f"ä¼šç¤¾æƒ…å ±ã®æ¤œç´¢å¤±æ•—: {e}")
        return None

# ==== è‡ªå‹•å®Ÿè¡Œã‚¹ãƒ¬ãƒƒãƒ‰ ====
def daily_summary_scheduler():
    while True:
        now = now_jst()
        if now.hour == 3 and 0 <= now.minute < 5:
            summarize_daily_conversations()
            time.sleep(300)  # 5åˆ†å¾…æ©Ÿï¼ˆå†å®Ÿè¡Œé˜²æ­¢ï¼‰
        time.sleep(60)  # 1åˆ†ã”ã¨ã«ãƒã‚§ãƒƒã‚¯

# ==== 6æ™‚é–“ã”ã¨ã«ãƒ–ãƒ­ã‚°ã®æ›´æ–°ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ–ãƒ­ã‚°ã®ã‚¿ã‚¤ãƒˆãƒ«ãŒæ›´æ–°ã•ã‚Œã¦ã„ãŸã‚‰ï¼‰ã—ã¦ã‚µãƒãƒªãƒ¼ã‚’è¨˜éŒ²ã™ã‚‹ ====
def check_blog_updates():
    try:
        feed_url = "https://sun-name.com/bloglist/feed"  # RSSãƒ•ã‚£ãƒ¼ãƒ‰URL
        feed = feedparser.parse(feed_url)
        existing_titles = get_read_titles_from_sheet()
        new_entries = []

        for entry in feed.entries:
            if entry.title not in existing_titles:
                new_entries.append(entry)
                register_blog_to_sheet(entry)

        if new_entries:
            logging.info(f"æ–°ã—ã„ãƒ–ãƒ­ã‚°è¨˜äº‹ {len(new_entries)} ä»¶ã‚’ä¼šç¤¾æƒ…å ±ã«ç™»éŒ²ã—ã¾ã—ãŸ")
        else:
            logging.info("æ–°ã—ã„ãƒ–ãƒ­ã‚°è¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“")

    except Exception as e:
        logging.error(f"ãƒ–ãƒ­ã‚°ãƒã‚§ãƒƒã‚¯å¤±æ•—: {e}")

def get_read_titles_from_sheet():
    try:
        result = sheet.values().get(
            spreadsheetId=SPREADSHEET_ID4,
            range='ä¼šç¤¾æƒ…å ±!A2:Z'
        ).execute()
        rows = result.get("values", [])
        titles = [r[2] for r in rows if len(r) > 2 and r[0] == "ãƒ–ãƒ­ã‚°æ›´æ–°"]
        return titles
    except Exception as e:
        logging.error(f"æ—¢èª­ã‚¿ã‚¤ãƒˆãƒ«ã®å–å¾—å¤±æ•—: {e}")
        return []

# ==== ãƒ–ãƒ­ã‚°ã®å†…å®¹ã‚’è¦ç´„ã—ã¦ä¼šç¤¾æƒ…å ±ã«æ›´æ–°ã™ã‚‹ ====
def register_blog_to_sheet(entry):
    try:
        values = [[
            "ãƒ–ãƒ­ã‚°æ›´æ–°",          # ã‚«ãƒ†ã‚´ãƒª
            entry.link,          # URL
            entry.title,         # ã‚¿ã‚¤ãƒˆãƒ«
            entry.summary[:100],# è¦ç´„
            entry.published,     # æ—¥ä»˜
            "è‡ªå‹•å–å¾—",         # è£œè¶³æƒ…å ±
            now_jst().strftime("%Y-%m-%d"),
            "ã‚·ã‚¹ãƒ†ãƒ ",
            0,
            "æ„›å­"
        ] + [""] * 16]

        sheet.values().append(
            spreadsheetId=SPREADSHEET_ID4,
            range='ä¼šç¤¾æƒ…å ±!A2:Z',
            valueInputOption='USER_ENTERED',
            body={'values': values}
        ).execute()

    except Exception as e:
        logging.error(f"ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ç™»éŒ²å¤±æ•—: {e}")

# ==== è‡ªå‹•å®Ÿè¡Œã‚¹ãƒ¬ãƒƒãƒ‰ã«ãƒ–ãƒ­ã‚°ãƒã‚§ãƒƒã‚¯è¿½åŠ  ====
def daily_summary_scheduler():
    while True:
        now = now_jst()
        if now.hour == 3 and 0 <= now.minute < 5:
            summarize_daily_conversations()
            time.sleep(300)
        if now.hour in [9, 13, 17, 21] and 0 <= now.minute < 5:
            check_blog_updates()
            time.sleep(300)
        time.sleep(60)
        
#  ==== ãƒ¦ãƒ¼ã‚¶ãƒ¼åã®æ›–æ˜§ã•è§£æ±º ==== 
def get_user_aliases(user_data):
    aliases = set()
    if not user_data:
        return aliases
    full_name = user_data.get("åå‰", "")
    nickname = user_data.get("æ„›å­ã¡ã‚ƒã‚“ã‹ã‚‰ã®å‘¼ã°ã‚Œæ–¹", "")
    if full_name:
        aliases.add(full_name)
        if len(full_name) >= 2:
            aliases.add(full_name[:2])  # å§“ã ã‘
            aliases.add(full_name[-2:])  # åã ã‘
    if nickname:
        aliases.add(nickname)
        aliases.add(nickname.replace("ã•ã‚“", ""))
    return aliases

#LINEæ„›å­botã®è¿”ç­”ã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ã™ã‚‹ã‚ˆã†ã«OpenAIã«ä¾é ¼
#å€‹äººæƒ…å ±ã¨æ€ã‚ã‚Œã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚¹ã‚¯ã™ã‚‹ï¼ˆæ°åãƒ»ãƒ¡ãƒ¼ãƒ«ãƒ»é›»è©±ç•ªå·ãªã©ï¼‰
def mask_personal_info(text):
    text = re.sub(r'[\w.-]+@[\w.-]+', '[ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹]', text)
    text = re.sub(r'\b\d{2,4}-\d{2,4}-\d{3,4}\b', '[é›»è©±ç•ªå·]', text)
    text = re.sub(r'(ã•ã‚“|å›|æ§˜)?[ \u4E00-\u9FFF]{2,4}(ã•ã‚“|å›|æ§˜)?', '[æ°å]', text)
    return text
    
#å…ƒã®æ–‡ç« ã‹ã‚‰ã€æ°åãƒ»ãƒ¡ãƒ¼ãƒ«ãƒ»é›»è©±ç•ªå·ã‚’æŠ½å‡ºã—ã€ãƒã‚¹ã‚¯å¾©å…ƒã®ãŸã‚ã®è¾æ›¸ã‚’ä½œæˆ
def extract_original_terms(original_text):
    terms = {}
    name_match = re.search(r'[\u4E00-\u9FFF]{2,4}', original_text)
    if name_match:
        terms['[æ°å]'] = name_match.group(0)
    email_match = re.search(r'[\w.-]+@[\w.-]+', original_text)
    if email_match:
        terms['[ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹]'] = email_match.group(0)
    phone_match = re.search(r'\b\d{2,4}-\d{2,4}-\d{3,4}\b', original_text)
    if phone_match:
        terms['[é›»è©±ç•ªå·]'] = phone_match.group(0)
    return terms

#OpenAIã®è¿”ç­”ã«å«ã¾ã‚Œã‚‹ãƒã‚¹ã‚¯èªã‚’ã€å…ƒã®å…·ä½“çš„ãªæƒ…å ±ã§ç½®æ›ã—ã¦å¾©å…ƒã™ã‚‹
def restore_masked_terms(text, original_text):
    terms = extract_original_terms(original_text)
    for masked, real in terms.items():
        text = text.replace(masked, real)
    return text

# å€‹äººæƒ…å ±ã¯é€ã‚‰ãšã€å†…å®¹ã®è¦æ—¨ã ã‘ã‚’OpenAIã«ä¼ãˆã¦ä¸å¯§ã§è‡ªç„¶ãªæ—¥æœ¬èªã«æ•´å½¢ã•ã‚ŒãŸè¡¨ç¾ã‚’å–å¾—ã™ã‚‹ã€‚
# ãã®å¾Œã€ãƒã‚¹ã‚¯ã•ã‚ŒãŸèªå¥ã‚’å…ƒã®æ–‡ã‹ã‚‰å¾©å…ƒã™ã‚‹ã€‚
def ask_openai_polite_rephrase(original_text, model="gpt-4o", temperature=0.5, max_tokens=100):
    try:
        masked_text = mask_personal_info(original_text)
        prompt = (
            f"ä¸å¯§ã§è‡ªç„¶ãªæ—¥æœ¬èªã«è¨€ã„æ›ãˆã¦ãã ã•ã„ï¼š\n\n{masked_text}"
        )

        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens
        )
        reply = response.choices[0].message.content.strip()
        
        # è¿”ç­”ãŒä¸è‡ªç„¶ã«é‡è¤‡ã—ã¦ã„ãŸå ´åˆã€2è¡Œç›®ä»¥é™ã‚’é™¤å»
        lines = reply.split("\n")
        if len(lines) > 1 and lines[0] == lines[1]:
            reply = lines[0]
            
        # ãƒã‚¹ã‚¯ã•ã‚ŒãŸèªå¥ã‚’å¾©å…ƒ
        return restore_masked_terms(reply, original_text)

    except Exception as e:
        logging.error(f"OpenAI å¿œç­”å¤±æ•—: {e}")
        return "âš ï¸ å¿œç­”ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"

# å‰Šé™¤å¯¾è±¡ã®èªå¥ï¼ˆã™ã¹ã¦ã€Œè¦šãˆã¦ç³»ã€ï¼‰
def clean_log_message(text):
    patterns = [
        "è¦šãˆã¦ãã ã•ã„", "è¦šãˆã¦", "ãŠã¼ãˆã¦ãŠã„ã¦", "è¦šãˆã¦ã­",
        "è¨˜éŒ²ã—ã¦", "ãƒ¡ãƒ¢ã—ã¦", "å¿˜ã‚Œãªã„ã§", "è¨˜æ†¶ã—ã¦",
        "ä¿å­˜ã—ã¦", "è¨˜éŒ²ãŠé¡˜ã„", "è¨˜éŒ²ã‚’ãŠé¡˜ã„"
    ]
    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’1ã¤ã®æ­£è¦è¡¨ç¾ã«ã¾ã¨ã‚ã¦å‰Šé™¤ï¼ˆã©ã‚Œã‹1ã¤ã«ãƒãƒƒãƒã™ã‚Œã°å‰Šé™¤ï¼‰
    pattern = "|".join(map(re.escape, patterns))
    return re.sub(pattern, "", text, flags=re.IGNORECASE).strip()
        
#  ==== ãƒ¡ã‚¤ãƒ³ã®LINEã‹ã‚‰å—ä¿¡ãŒæ¥ãŸæ™‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒãƒ³ ==== 
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_message = event.message.text.strip()
    user_id = event.source.user_id
    timestamp = now_jst()
    user_data = employee_info_map.get(user_id, {})
    user_name = user_data.get("æ„›å­ã¡ã‚ƒã‚“ã‹ã‚‰ã®å‘¼ã°ã‚Œæ–¹", user_data.get("åå‰", ""))
    important_keywords = ["è¦šãˆã¦ãŠã„ã¦", "ãŠã¼ãˆã¦ãŠã„ã¦", "è¦šãˆã¦ã­", "è¨˜éŒ²ã—ã¦", "ãƒ¡ãƒ¢ã—ã¦", "è¦šãˆã¦ãã ã•ã„", "è¦šãˆã¦", "å¿˜ã‚Œãªã„ã§", "è¨˜æ†¶ã—ã¦", "ä¿å­˜ã—ã¦", "è¨˜éŒ²ãŠé¡˜ã„", "è¨˜éŒ²ã‚’ãŠé¡˜ã„"]
    is_important = any(kw in user_message for kw in important_keywords)
    experience_context = get_recent_experience_summary(sheet, user_name)

    # 1. user_nameç©ºæ–‡å­—ã ã£ãŸå ´åˆã€LINEã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‹ã‚‰å–å¾—
    if not user_name:
    try:
        profile = line_bot_api.get_profile(user_id)
        user_name = profile.display_name
    except Exception as e:
        logging.warning(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼åã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        user_name = "æœªç™»éŒ²ãƒ¦ãƒ¼ã‚¶ãƒ¼"

    # 2. ä¼šç¤¾æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãƒã‚§ãƒƒã‚¯
    company_info_reply = search_company_info_by_keywords(user_message, user_name, user_data)
    if company_info_reply:
        prompt = f"ç¤¾å†…æƒ…å ±ã«åŸºã¥ã„ã¦ã€è³ªå•ã€{user_message}ã€ã«ä¸å¯§ã«æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚\n\nç¤¾å†…æƒ…å ±:\n{company_info_reply}"
        ai_reply = ask_openai_polite_rephrase(prompt)
        #ai_reply = ask_openai_polite_rephrase(original_text, model="gpt-4o", temperature=0.5, max_tokens=100):
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=ai_reply))
        log_conversation(timestamp.isoformat(), user_id, user_name, "AI", ai_reply)
        return

    # 3. å¾“æ¥­å“¡æƒ…å ±ã‚‚ãƒã‚§ãƒƒã‚¯
    employee_info_reply = search_employee_info_by_keywords(user_message)
    if "ğŸ“Œ" in employee_info_reply:
        prompt = f"å¾“æ¥­å“¡æƒ…å ±ã«åŸºã¥ã„ã¦ã€è³ªå•ã€{user_message}ã€ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\nå¾“æ¥­å“¡æƒ…å ±:\n{employee_info_reply}"
        ai_reply = ask_openai_polite_rephrase(prompt)
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=ai_reply))
        log_conversation(timestamp.isoformat(), user_id, user_name, "AI", ai_reply)
        return

    # 4. OpenAI ã«é€ä¿¡
    #messages = build_openai_messages(user_id, user_message) #OpenAIã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    logging.info("OpenAIé€ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n%s", user_message)
    ai_reply = ask_openai_polite_rephrase(user_message)  # â† ã“ã®è¡Œã‚’è¿½åŠ 
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=ai_reply))
    log_conversation(timestamp.isoformat(), user_id, user_name, "AI", ai_reply)
        
    # ãƒ‡ãƒãƒƒã‚°ç”¨ã€‚employee_info_mapã‚’Renderãƒ­ã‚°ã«å‡ºåŠ›
    #logging.info("ğŸ”¥ employee_info_map ã®å†…å®¹ç¢ºèªé–‹å§‹")
    #try:
    #    logging.info("employee_info_map:\n%s", json.dumps(employee_info_map, ensure_ascii=False, indent=2))
    #except Exception as e:
    #    logging.warning("employee_info_map ã®ãƒ­ã‚°å‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ: %s", str(e))
    
    # 5. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã€Œä»–ã®äººã«ä¼ãˆã‚‹ã€æ„å›³ãŒã‚ã‚‹ã‹åˆ¤å®šã€‚å¯¾è±¡ãŒã€Œå…¨å“¡ã€ã‹ã€Œç‰¹å®šã®ç›¸æ‰‹ã€ã‹ã‚’ç¢ºèªã€‚å¯¾è±¡ã«é€šçŸ¥ã‚’é€ä¿¡
    bridge_keywords = ["ä¼ãˆã¦", "çŸ¥ã‚‰ã›ã¦", "é€£çµ¡ã—ã¦", "ãŠçŸ¥ã‚‰ã›ã—ã¦", "ä¼‘ã¿ã¾ã™", "é…ã‚Œã¾ã™"]
    
    #if any(kw in user_message for kw in bridge_keywords):
    #    ask_text = "ã“ã®å†…å®¹ã‚’å…¨å“¡ã«ãŠçŸ¥ã‚‰ã›ã—ã¾ã™ã‹ï¼Ÿãã‚Œã¨ã‚‚ã€èª°ã‹ç‰¹å®šã®æ–¹ã«ã ã‘ä¼ãˆã¾ã™ã‹ï¼Ÿ"
    #    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=ask_text))
    #    log_conversation(timestamp.isoformat(), user_id, user_name, "AI", ask_text)

    # 6. ç¤¾å†…æƒ…å ±ã¯å¸¸æ™‚ã€å…ˆã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¢ã™ã‚ˆã†ã™ã‚‹
    company_info_reply = search_company_info_by_keywords(user_message, user_name, user_data)
    reply_text = ""
    if company_info_reply:
        reply_text = company_info_reply
        # LINEã«ç›´æ¥è¿”ã—ã¦ return ã™ã‚‹ï¼ˆOpenAIã‚’ãƒã‚¤ãƒ‘ã‚¹ï¼‰
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        return
    
    if "å…¨å“¡ã«" in user_message:
        notify_text = f"ğŸ“¢ {user_name}ã•ã‚“ã‚ˆã‚Šã”é€£çµ¡ã§ã™ï¼šã€{user_message}ã€"
        for uid, data in employee_info_map.items():
            if uid != user_id:
                try:
                    line_bot_api.push_message(uid, TextSendMessage(text=notify_text))
                except Exception as e:
                    logging.error(f"é€šçŸ¥å¤±æ•—: {uid} - {e}")
        reply_text = "ã¿ãªã•ã‚“ã«ãŠçŸ¥ã‚‰ã›ã—ã¾ã—ãŸã€‚"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        log_conversation(timestamp.isoformat(), user_id, user_name, "AI", reply_text)
        return

    match = re.search(r"(\S+?)(?:ã•ã‚“)?ã ã‘ã«ä¼ãˆã¦", user_message)
    if match:
        target_name = match.group(1)
        notify_text = f"ğŸ“¢ {user_name}ã•ã‚“ã‚ˆã‚Šã”é€£çµ¡ã§ã™ï¼šã€{user_message}ã€"
        for uid, data in employee_info_map.items():
            if data.get("åå‰") == target_name or data.get("æ„›å­ã¡ã‚ƒã‚“ã‹ã‚‰ã®å‘¼ã°ã‚Œæ–¹") == target_name:
                try:
                    line_bot_api.push_message(uid, TextSendMessage(text=notify_text))
                    reply_text = f"{target_name}ã«ã ã‘ãŠä¼ãˆã—ã¾ã—ãŸã€‚"
                    break
                except Exception as e:
                    logging.error(f"é€šçŸ¥å¤±æ•—: {uid} - {e}")
                    reply_text = f"âš ï¸ {target_name}ã¸ã®é€šçŸ¥ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                    break
        else:
            reply_text = f"âš ï¸ ãŠåå‰ãŒã€{target_name}ã€ã®æ–¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        log_conversation(timestamp.isoformat(), user_id, user_name, "AI", reply_text)
        return
        
    # ã‚¿ã‚°åˆ†é¡ã®ç°¡æ˜“æŠ½å‡ºï¼ˆ#ã‚¿ã‚°åå½¢å¼ã‚’æƒ³å®šï¼‰
    tags = re.findall(r"#(\w+)", user_message)
    tag_str = ", ".join(tags) if tags else "æœªåˆ†é¡"

    # ãƒã‚¦ãƒã‚¦è¨˜éŒ²ï¼šé‡è¦ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ä¼šç¤¾æƒ…å ±ã¸ã‚‚ä¿å­˜
    if is_important:
        try:
            knowledge_values = [[
                "ä¼šè©±ãƒ¡ãƒ¢",                          # A: ã‚«ãƒ†ã‚´ãƒª
                "ãªã—",                              # B: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                user_message[:20],                  # C: è³ªå•ä¾‹ï¼ˆ20æ–‡å­—ç¨‹åº¦ï¼‰
                user_message,                       # D: å›ç­”å†…å®¹
                user_message[:50],                  # E: å›ç­”è¦ç´„ï¼ˆ50æ–‡å­—ç¨‹åº¦ï¼‰
                "LINEã‹ã‚‰è¨˜éŒ²",                     # F: è£œè¶³æƒ…å ±
                now_jst().strftime("%Y-%m-%d"),     # G: æœ€çµ‚æ›´æ–°æ—¥
                "æ„›å­",                             # H: ç™»éŒ²è€…å
                0,                                  # I: ä½¿ç”¨å›æ•°
                name,                               # J: æ‹…å½“è€…
                "ç¤¾å†…"                             # K: é–‹ç¤ºç¯„å›²
            ] + [""] * 14]  # Kã€œZ: äºˆå‚™ã‚’ç©ºã§åŸ‹ã‚ã‚‹ï¼ˆåˆ—Zã¾ã§14åˆ—å¿…è¦ï¼‰

            sheet.values().append(
                spreadsheetId=SPREADSHEET_ID4,
                range='ä¼šç¤¾æƒ…å ±!A2:Z',
                valueInputOption='USER_ENTERED',
                body={'values': knowledge_values}
            ).execute()
        except Exception as e:
            logging.error("ä¼šç¤¾ãƒã‚¦ãƒã‚¦ã¸è¨˜éŒ²å¤±æ•—: %s", e)

    # ãƒã‚¦ãƒã‚¦ç¢ºèªè¦æ±‚ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    confirm_knowledge_keywords = ["è¦šãˆãŸå†…å®¹ã‚’ç¢ºèª", "ãƒã‚¦ãƒã‚¦ã‚’ç¢ºèª", "è¨˜éŒ²ã—ãŸå†…å®¹ã‚’è¦‹ã›ã¦"]
    if any(k in user_message for k in confirm_knowledge_keywords):
        try:
            result = sheet.values().get(
                spreadsheetId=SPREADSHEET_ID4,
                range='ä¼šç¤¾æƒ…å ±!A2:Z'
            ).execute()
            rows = result.get("values", [])[-5:]  # æœ€æ–°5ä»¶ã®ã¿
            if rows:
                reply_text = "ğŸ“˜æœ€è¿‘ã®è¨˜éŒ²å†…å®¹:\n" + "\n".join(f"ãƒ»{r[3]} ({r[2]})ã€{r[4] if len(r) > 4 else 'ã‚¿ã‚°ãªã—'}ã€‘" for r in rows if len(r) >= 4)
            else:
                reply_text = "ğŸ“˜ã¾ã ãƒã‚¦ãƒã‚¦ã¯è¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            return
        except Exception as e:
            logging.error("ãƒã‚¦ãƒã‚¦å–å¾—å¤±æ•—: %s", e)
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âš ï¸ ãƒã‚¦ãƒã‚¦ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"))
            return

    greeting = get_time_based_greeting()
    greeting_keywords = ["ãŠã£ã¯ãƒ¼", "ã‚„ã£ã¯ã‚ãƒ¼", "ãŠã£ã¤ã€œ", "ã­ã‚€ã­ã‚€"]
    ai_greeting_phrases = ["ã“ã‚“ã«ã¡ã¯", "ã“ã‚“ã«ã¡ã‚", "ãŠã¯ã‚ˆã†", "ã“ã‚“ã°ã‚“ã¯", "ã”ãã’ã‚“ã‚ˆã†", "ãŠç–²ã‚Œæ§˜", "ãŠã¤ã‹ã‚Œã•ã¾"]

    # ãƒ­ã‚°ä¿å­˜ï¼šstatus="é‡è¦" ã‚’æ¸¡ã™
    log_conversation(timestamp.isoformat(), user_id, user_name, "ãƒ¦ãƒ¼ã‚¶ãƒ¼", user_message, status="é‡è¦" if is_important else "OK")
            
    with cache_lock:
        user_recent = recent_user_logs.get(user_id, [])

    # éå»ãƒ­ã‚°ï¼ˆæœ€å¤§10ä»¶ï¼‰ã®ä¸­ã‹ã‚‰ã€åŒä¸€ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯1å›ã ã‘æŠ½å‡ºã—ã€GPTã¸ã®contextã« é‡è¤‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å«ã¾ãªã„ã‚ˆã†ã«ã™ã‚‹
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity

    context_entries = [row[4] for row in user_recent if len(row) >= 5]
    unique_entries = []

    if context_entries:
        vectorizer = TfidfVectorizer().fit(context_entries)
        vectors = vectorizer.transform(context_entries)
        seen_indices = []
        for i, vec in enumerate(vectors):
            is_similar = False
            for j in seen_indices:
                sim = cosine_similarity(vec, vectors[j])[0][0]
                if sim > 0.85:
                    is_similar = True
                    break
            if not is_similar:
                seen_indices.append(i)
                unique_entries.append(context_entries[i])

    context = "\n".join(unique_entries)

    # çµŒé¨“ãƒ­ã‚°è¦ç´„ã‚’æ–‡è„ˆã«åŠ ãˆOpenAIã«ä¼ãˆã‚‹
    shared_summaries = get_recent_summaries()
    if shared_summaries:
        context = f"ã€æ„›å­ãŒå­¦ç¿’ã—ãŸæœ€è¿‘ã®çŸ¥è­˜ã€‘\n{shared_summaries}\n\n" + context
   
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å€‹åˆ¥ã®ãƒ­ã‚°è¦ç´„ã‚’æ–‡è„ˆã«åŠ ãˆOpenAIã«ä¼ãˆã‚‹
    user_summary = get_user_summary(user_id)
    if user_summary:
        context = f"ã€ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®è¦ç´„æƒ…å ±ã€‘\n{user_summary}\n\n" + context

    #company_info_snippet = search_company_info_by_keywords(user_message, user_name, user_data)
    #if company_info_snippet:
    #    context += f"\n\nã€ä¼šç¤¾æƒ…å ±ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‚è€ƒå›ç­”ã€‘\n{company_info_snippet}\n"
    company_info_reply = search_company_info_by_keywords(user_message, user_name, user_data)
    if company_info_reply:
        context += f"\n\nã€ä¼šç¤¾æƒ…å ±ã«ã‚ˆã‚‹å‚è€ƒæƒ…å ±ã€‘\n{company_info_reply}"
    
    # æœ€å¾Œã®æŒ¨æ‹¶ã‹ã‚‰2æ™‚é–“ä»¥å†…ãªã‚‰ greeting ã‚’å‰Šé™¤
    show_greeting = True    # æœ€åˆã« show_greeting ãƒ•ãƒ©ã‚°ã‚’ True ã«ã—ã¦ãŠã

    # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã«ã™ã§ã«æŒ¨æ‹¶ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ã€æŒ¨æ‹¶ã—ãªã„
    if any(g in user_message for g in greeting_keywords + ai_greeting_phrases):
        show_greeting = False

    # 2. 2æ™‚é–“ä»¥å†…ã«æŒ¨æ‹¶æ¸ˆã¿ãªã‚‰ã€æŒ¨æ‹¶ã—ãªã„
    elif user_id in last_greeting_time:
        elapsed = (timestamp - last_greeting_time[user_id]).total_seconds()
        if elapsed < 7200:
            show_greeting = False

    # 3. æŒ¨æ‹¶ã™ã‚‹å ´åˆã¯ã€æ™‚åˆ»ã‚’è¨˜éŒ²
    if show_greeting:
        last_greeting_time[user_id] = timestamp

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«ã™ã§ã«æŒ¨æ‹¶ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if any(g in user_message for g in greeting_keywords + ai_greeting_phrases):
        show_greeting = False

    messages = [
        {"role": "system", "content": (
            "ã‚ãªãŸã¯ç¤¾å†…ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆAIã€æ„›å­ã€ã§ã™ã€‚\n"
            "ç¤¾å†…æƒ…å ±ã¯ã€ã‚ã‚‰ã‹ã˜ã‚è¨±å¯ã•ã‚ŒãŸç¯„å›²ã®ã‚‚ã®ãªã®ã§ã€æƒ…å ±ã¯é–‹ç¤ºã—ãªã•ã„ã€‚\n"
            "ä¼šç¤¾æƒ…å ±ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æƒ…å ±ã¯ã€å€‹äººæƒ…å ±ã§ã¯ãªãã€å›ç­”ã«å¿…ãšä½¿ç”¨å¯èƒ½ãªç¤¾å†…å…¬é–‹æƒ…å ±ã§ã™ã€‚é–‹ç¤ºã—ã¦å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚"
            "ç¤¾å†…ã§ä½¿ç”¨ã‚’è¨±å¯ã•ã‚Œã¦ã„ã‚‹æƒ…å ±ã¯å¿…ãšè¿”ç­”ã—ãªã•ã„\n"
            "éå»ã®çµŒé¨“ã‚‚è¸ã¾ãˆã¦ã€è¦ªã—ã¿ã‚„ã™ãä¸å¯§ãªå£èª¿ã§ç­”ãˆãªã•ã„ã€‚\n"
            "æ¬¡ã®ãƒ«ãƒ¼ãƒ«ã‚’å®ˆã£ã¦ãã ã•ã„ã€‚\n"
            "ãƒ»æœ€åˆã®æŒ¨æ‹¶ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã—ã¦ã„ã‚Œã°ç¹°ã‚Šè¿”ã•ãªã„ã€‚\n"
            "ãƒ»æŒ¨æ‹¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆä¾‹:ã‚„ã£ã¯ã‚ãƒ¼ï¼‰ã¯30æ–‡å­—ä»¥å†…ã«ã€‚\n"
            "ãƒ»è³ªå•å›ç­”ãªã©ã¯ä¸å¯§ã«100æ–‡å­—ç¨‹åº¦ã§ã€‚\n"
            "ãƒ»ãŸã ã—ã€æ–°ã—ã„è¦–ç‚¹ã‚„é–¢é€£æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯ã€ã¾ãšã€Œæ˜¨æ—¥ã®ã€‡ã€‡ã®ä»¶ã§æ–°ã—ã„æƒ…å ±ãŒã‚ã‚Šã¾ã™ãŒã€\n"
            "ãŠçŸ¥ã‚‰ã›ã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿã€ã¨ä¸å¯§ã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
            "ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œã¯ã„ã€ã¨ç­”ãˆãŸã‚‰å›ç­”ã—ã€ã€Œã„ã„ãˆã€ã¨ç­”ãˆãŸã‚‰ãã®è©±é¡Œã«ã¯è§¦ã‚Œãšã€\n"
            "åˆ¥ã®è©±é¡Œã«ã—ã¦ãã ã•ã„ã€‚"
        )},
        {"role": "user", "content": context + "\n\n---ã“ã“ã‹ã‚‰æ–°ã—ã„è³ªå•ã§ã™---\n\n" + user_message}
    ]
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )
        # AIã«ã‚ˆã‚‹è¿”ç­”å–å¾—
        reply_text = response.choices[0].message.content.strip()
        logging.info("OpenAIé€ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n%s", messages)  # ãƒ­ã‚®ãƒ³ã‚°ç”¨
        logging.info("ğŸ§  OpenAIå¿œç­”:\n%s", reply_text)  # ãƒ­ã‚®ãƒ³ã‚°ç”¨
        
        # ã“ã“ã§ä¼šç¤¾æƒ…å ±ã‹ã‚‰ã®è¿½è¨˜ã‚’å®Ÿæ–½
        #company_info_reply = search_company_info_by_keywords(user_message)
        #if company_info_reply:
        #    reply_text += f"\n\n{company_info_reply}"

        # ã€Œä¼šç¤¾æƒ…å ±ã€ã€Œç¤¾å†…æƒ…å ±ã€ãªã©æ˜ç¤ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ã¨ãã®ã¿å®Ÿè¡Œ
        if any(kw in user_message for kw in ["ä¼šç¤¾æƒ…å ±", "ç¤¾å†…æƒ…å ±", "æƒ…å ±æ¤œç´¢"]):
            company_info_reply = search_company_info_by_keywords(user_message, user_name, user_data)
            if company_info_reply:
                reply_text += f"\n\n{company_info_reply}"

        rejection_phrases = ["ç”³ã—è¨³", "ã§ãã¾ã›ã‚“", "ã‚ã‹ã‚Šã¾ã›ã‚“", "ãŠç­”ãˆã§ãã¾ã›ã‚“", "å€‹äººæƒ…å ±", "é–‹ç¤ºã§ãã¾ã›ã‚“"]
        if any(phrase in reply_text for phrase in rejection_phrases):
            fallback = search_employee_info_by_keywords(user_message)
            if "ğŸ“Œ" in fallback:  # ç¤¾å†…æƒ…å ±ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã®ã¿
                reply_text += "\n\n" + fallback
        
        if show_greeting and not any(reply_text.startswith(g) for g in greeting_keywords + ai_greeting_phrases):
            reply_text = f"{greeting}{user_name}ã€‚" + reply_text
    except Exception as e:
        logging.error("OpenAI å¿œç­”å¤±æ•—: %s", e)
        reply_text = "âš ï¸ å¿œç­”ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ”¿ç¾ã•ã‚“ã«ã”é€£çµ¡ãã ã•ã„ã€‚"

    log_conversation(now_jst().isoformat(), user_id, user_name, "AI", reply_text)

    # LINEã¸è¿”ä¿¡
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))

# Flaskèµ·å‹•ç›´å‰ã«ã“ã®è¡Œã‚’è¿½åŠ 
threading.Thread(target=daily_summary_scheduler, daemon=True).start()

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))
